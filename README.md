# ML_Based-RealTime_Expression_Tracker
ğŸ§  Real-time Facial Expression Recognition using OpenCV, Mediapipe, and Deep Learning â€” detects human emotions live via webcam.

# ğŸ˜ƒ Real-Time Expression Tracker

A **real-time facial expression recognition system** that uses **computer vision** and **deep learning** to detect human emotions live from a webcam feed.  
It identifies expressions like **happy, sad, angry, surprised, neutral, fear, and disgust** â€” and displays the detected emotion directly on the live video window.

---

## ğŸš€ Overview

This project leverages **OpenCV** and **Deep Learning** to perform live emotion detection.  
It processes real-time webcam frames, detects faces, extracts key facial features, and classifies the expression using a trained model.  
Useful for:
- Human-computer interaction  
- Mental state analysis  
- AI-based interview or mood-tracking systems  

---

## âœ¨ Features

âœ… Real-time face detection using **OpenCV**  
âœ… Emotion classification (Happy, Sad, Angry, etc.)  
âœ… Works smoothly on CPU â€” no GPU required  
âœ… Lightweight, fast, and easy to run  
âœ… Modular and ready to integrate with other AI systems  

---

## ğŸ§  Tech Stack

| Category | Technologies Used |
|-----------|------------------|
| **Language** | Python 3.8+ |
| **Computer Vision** | OpenCV, Mediapipe |
| **Machine Learning** | TensorFlow / PyTorch (depending on your model) |
| **Libraries** | NumPy, Pandas, Scikit-learn, Matplotlib |
| **IDE (Recommended)** | PyCharm |

---

## ğŸ“ Project Structure

LieDetectionProject/
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ realtime_lie_detection.py # Main script (expression tracker)
â”‚ â”œâ”€â”€ face_detector.py # Face detection module (optional)
â”‚ â”œâ”€â”€ emotion_model.py # Model loading and prediction
â”‚ â””â”€â”€ utils.py # Helper functions
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ expression_model.pth # Trained emotion recognition model
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ venv/

## âš™ï¸ Installation Guide

### 1ï¸âƒ£ Clone the Repository
git clone https://github.com/<your-username>/RealTime-Expression-Tracker.git
cd RealTime-Expression-Tracker

2ï¸âƒ£ Create and Activate Virtual Environment
python -m venv venv
.\venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

Or install manually:
pip install opencv-python mediapipe torch torchvision numpy pandas matplotlib scikit-learn

â–¶ï¸ Running the Project
Make sure your webcam is connected, then run:
python scripts/realtime_lie_detection.py

ğŸ“Š Detected Emotions
The model can identify the following emotions:

ğŸ˜€ Happy

ğŸ˜¢ Sad

ğŸ˜  Angry

ğŸ˜± Surprised

ğŸ˜ Neutral

ğŸ˜¨ Fear

ğŸ¤¢ Disgust

Each detected emotion is displayed in real time on the video frame.

ğŸ§© Requirements File Example
If not created yet, hereâ€™s a sample requirements.txt:
opencv-python
mediapipe
torch
torchvision
numpy
pandas
scikit-learn
matplotlib

ğŸ’¡ Future Improvements
ğŸš€ Add support for multiple faces
ğŸ§  Improve accuracy with CNN / transformer-based models
ğŸ™ï¸ Combine facial + voice emotion detection
ğŸŒ Deploy with Flask/Streamlit dashboard

ğŸ‘¨â€ğŸ’» Author
Developed by: Shiv Chandra Bind
ğŸ“§ Email: bdrdshivchandra9125@gmail.com
ğŸ’» Passionate about Computer Vision & Real-Time AI Systems

ğŸªª License
This project is released under the MIT License â€” free for personal and educational use.
